{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0CfES-nFOJ0"
   },
   "source": [
    "# **BERT en Español**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbFbgqwdFSa0",
    "outputId": "f318ac4f-07d6-485d-9197-bb9221843645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/juliotorres/miniconda3/lib/python3.11/site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: torch in /home/juliotorres/miniconda3/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.8.0)\n",
      "Requirement already satisfied: wheel in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from triton==2.0.0->torch) (3.27.5)\n",
      "Requirement already satisfied: lit in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6gsD1xlFngH",
    "outputId": "7aa7d315-5f27-47ee-c7ad-b9426b69d4e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 19:30:01.533440: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-25 19:30:01.561628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e2cff48e9d4f42bdd25713d5671aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e54dd8773b41d8adb2589e6197977a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8122ac9c1c4f77b0c3ddfaf30ad39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeca7bfd973e4cb0b64541cff9061932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a908cea645014e9ea3ddf8f913d7b42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.33.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "\n",
    "model_name = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "print (config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooYAkF-UF68q",
    "outputId": "72e6f801-2dd1-4f21-a287-152d777c25cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Está', 'haciendo', 'mucho', 'calor']\n",
      "[4, 1700, 2391, 1789, 7110, 5]\n"
     ]
    }
   ],
   "source": [
    "input_text = 'Está haciendo mucho calor'\n",
    "tokens = tokenizer.tokenize(input_text)\n",
    "codes = tokenizer.encode(input_text)\n",
    "print (tokens)\n",
    "print (codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92UGCKXwzg70",
    "outputId": "b0043256-a8ce-4a58-a280-fbb15674a85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario de BETO: 31002\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamaño del vocabulario de BETO: {len(tokenizer.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZInLkhE198a",
    "outputId": "8b118114-170d-44c2-8e6b-c1c08a1aba47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1965, 8312, 1036, 4436, 1355, 1216, 6072, 1042, 1051, 1216, 1248, 7712, 1019, 1042, 1007, 13961, 30934, 5]\n"
     ]
    }
   ],
   "source": [
    "text = 'Una sentencia en español pero más larga y con más tildes y eñes'\n",
    "tokens = tokenizer.encode(text) # obtener las ids de los tokesn para el vocabulario de BETO\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "c1PkkCSk9o-n",
    "outputId": "7039268b-9ec9-4b5f-88d4-729788b7b9f8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[CLS] Una sentencia en español pero más larga y con más tildes y eñes [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decode reconstruirá la sentencia con el añadido de [CLS] y [SEP]\n",
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQxfquAX-5sq",
    "outputId": "69bfc0b4-a72e-4307-f52a-74777f94f7a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 4, subpalabra: [CLS]\n",
      "Token: 1965, subpalabra: Una\n",
      "Token: 8312, subpalabra: sentencia\n",
      "Token: 1036, subpalabra: en\n",
      "Token: 4436, subpalabra: español\n",
      "Token: 1355, subpalabra: pero\n",
      "Token: 1216, subpalabra: más\n",
      "Token: 6072, subpalabra: larga\n",
      "Token: 1042, subpalabra: y\n",
      "Token: 1051, subpalabra: con\n",
      "Token: 1216, subpalabra: más\n",
      "Token: 1248, subpalabra: ti\n",
      "Token: 7712, subpalabra: ##ld\n",
      "Token: 1019, subpalabra: ##es\n",
      "Token: 1042, subpalabra: y\n",
      "Token: 1007, subpalabra: e\n",
      "Token: 13961, subpalabra: ##ñe\n",
      "Token: 30934, subpalabra: ##s\n",
      "Token: 5, subpalabra: [SEP]\n"
     ]
    }
   ],
   "source": [
    "# una forma de imprimir ids y string de los tokens\n",
    "for t in tokens:\n",
    "    print (f'Token: {t}, subpalabra: {tokenizer.decode( [t] )}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5m0YvoAI9AMj",
    "outputId": "036d7b7d-8383-499a-8a1a-ab41e26bb425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ti', '##ld', '##es']\n",
      "[4, 1248, 7712, 1019, 5]\n"
     ]
    }
   ],
   "source": [
    "input_text = 'tildes'\n",
    "tokens = tokenizer.tokenize(input_text)\n",
    "codes = tokenizer.encode(input_text)\n",
    "print (tokens)\n",
    "print (codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yW86k_gJ-gcO",
    "outputId": "d2726f40-8c60-4984-b1e2-47ba779a9942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', '##ñe', '##s']\n",
      "[4, 1007, 13961, 30934, 5]\n"
     ]
    }
   ],
   "source": [
    "input_text = 'eñes'\n",
    "tokens = tokenizer.tokenize(input_text)\n",
    "codes = tokenizer.encode(input_text)\n",
    "print (tokens)\n",
    "print (codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hq_aGEb0CzAF",
    "outputId": "e76ee3b7-3739-4719-9db0-14a1e7c3d89f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [4, 1965, 2274, 1129, 10470, 1269, 1365, 1675, 1042, 1129, 1131, 16672, 1009, 1001, 30938, 2345, 2600, 5], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "texto = \"Una persona me habló sobre este lugar y me ha gustado. Él tenía razón\"\n",
    "#encode_plus nos devuelve las ids de los tokens, la máscara de atención y segmenta ids (A vs B). Útil en tiempo de entrenamiento\n",
    "tokens = tokenizer.encode_plus(texto)\n",
    "print (tokens)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
